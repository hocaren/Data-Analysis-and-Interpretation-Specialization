# Data-Analysis-and-Interpretation-Specialization
# Coursera Machine Learning Data Analysis

we learn from the data. We use a subset of observations from our dataset, which we call the training set, to learn about the data. And then test the statistical model we get from the training data set on a different set of observations which we call the test set. We split the data this way because the model that is fit using a machine learning approach is going to fit best in the data set on which it was developed. But it might not perform as well when we try to test it on a different set of observations. If the model doesn't work for a different data set then it's not of much use even if it fits well in the training data set. When we apply our statistical model from the training data set to the test data set, we're interested primarily in the accuracy of our statistical model. Accuracy can be assessed by what is called the test error rate, which is a measure of the extent to which a model correctly classifies observations into categories. Or correctly estimates the value of a different variable of interest for each observation in the test data set. The goal then is to identify a model that minimizes the test error rate.
